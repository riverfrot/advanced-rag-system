#!/usr/bin/env python3
"""
Issue Query & Resolution Pipeline
Issue ë²ˆí˜¸ ì…ë ¥ â†’ VectorStore ê²€ìƒ‰ â†’ Tavily API ë¦¬ì„œì¹˜ â†’ OpenAI ChatCompletionìœ¼ë¡œ í•´ê²°ì±… ìƒì„±
"""

import os
import sys
import argparse
from typing import List, Dict, Any
from dotenv import load_dotenv

from langchain_community.vectorstores import Chroma
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from tavily import TavilyClient
import os
from datetime import datetime
from langchain_core.messages import SystemMessage, HumanMessage

load_dotenv()

# LangSmith ì¶”ì  í™œì„±í™”
os.environ["LANGCHAIN_TRACING_V2"] = "true"
if os.getenv("LANGCHAIN_API_KEY"):
    os.environ["LANGCHAIN_PROJECT"] = os.getenv("LANGCHAIN_PROJECT", "rag-system")


class IssueQuerySystem:
    def __init__(self):
        # API í‚¤ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.tavily_api_key = os.getenv("TAVILY_API_KEY")

        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        if not self.tavily_api_key:
            raise ValueError("TAVILY_API_KEY not found in environment variables")

        # LangChain ChatOpenAI ì´ˆê¸°í™” (LangSmith ì¶”ì  ê°€ëŠ¥)
        self.llm = ChatOpenAI(
            model="gpt-4", temperature=0.7, max_tokens=2000, api_key=self.openai_api_key
        )

        # Embeddings ì´ˆê¸°í™” (crawl.pyì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš© í•´ì•¼í•¨ ì•„ë‹ˆë©´ ì •ìƒì ìœ¼ë¡œ ê²€ìƒ‰ì´ ë˜ì§€ì•ŠìŒ
        # ì¶”í›„ í¬ìŠ¤íŒ… ì˜ˆì •)
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small", api_key=self.openai_api_key
        )

        # Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.tavily_client = TavilyClient(api_key=self.tavily_api_key)

        # ChromaDB ì„¤ì •
        self.chroma_persist_dir = os.getenv("CHROMA_PERSIST_DIRECTORY", "./chroma_db")
        self.vectorstore = None

    def load_vector_store(self) -> None:
        print(f"Get Vector stor: ${self.chroma_persist_dir}")

        try:
            self.vectorstore = Chroma(
                persist_directory=self.chroma_persist_dir,
                embedding_function=self.embeddings,
            )
        except Exception as e:
            print(f" Error vector load : {e}")
            raise

    def search_relevant_context(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """VectorStoreì—ì„œ ê´€ë ¨ëœ ì½”ë“œ ê²€ìƒ‰"""
        print(f"quety: {query}")

        if not self.vectorstore:
            self.load_vector_store()

            # ê¸°ì¡´ ë¡œë“œí•œ github ëŒ€ìƒìœ¼ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            # í˜„ì¬ëŠ” ë‹¨ì¼ í”„ë¡œì íŠ¸ë¡œë§Œ ê°€ëŠ¥í•˜ë‚˜ ì¶”í›„ githubë¥¼ ë‹¤ì¤‘ì„ë¡œ êµ¬ì„±í•˜ì—¬ ì¿¼ë¦¬ ê°€ëŠ¥í•˜ê²Œë” êµ¬ì¡° ê°œì„  í•„ìš”

            # ë””í´íŠ¸ ê°’ìœ¼ë¡œ 5ê°œì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ë‚´ìš©ë§Œ ê°€ì ¸ì˜¤ê²Œë” ìˆ˜ì •
            # ì¶”í›„ dense retrivalë¿ë§Œ ì•„ë‹Œ, sparse retrivalì´ ê°€ëŠ¥í•˜ê²Œë” ìˆ˜ì •
            # í˜„ì¬ëŠ” ì •í™•í•˜ê²Œ ì¼ì¹˜ë˜ëŠ” ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ê²ƒì—ëŠ” í•œê³„ê°€ ì¡´ì¬...
            result = self.vectorstore.similarity_search_with_score(query, k=k)

            context_docs = []
            for doc, score in result:
                context_docs.append(
                    {
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "similarity_score": float(score),
                    }
                )
                print(
                    f"content : {doc.page_content}, metadata: {doc.metadata}, score : {float(score)}"
                )

            print(f"ê´€ë ¨ ê²€ìƒ‰ code data {len(context_docs)}")
            print(f"{context_docs}")

            return context_docs

    def tavily_resarch(self, query: str) -> str:
        """Tavily APIë¥¼ í™œìš©í•œ ì›¹ê²€ìƒ‰"""
        try:
            # Tavily search
            response = self.tavily_client.search(
                query=query, search_depth="advanced", max_results=3, include_answer=True
            )

            print(f"response: {response}")

            research_content = ""

            if response.get("answer"):
                research_content += f"Research Summary: {response['answer']}\n\n"

            for i, result in enumerate(response.get("results", []), 1):
                research_content += f"Result {i}:\n"
                research_content += f"Title: {result.get('title', 'N/A')}\n"
                research_content += f"Content: {result.get('content', 'N/A')}\n"
                research_content += f"URL: {result.get('url', 'N/A')}\n\n"

            return research_content
        except Exception as e:
            print(f"research failed : {e}")
            return "api error"

    def generate_solution(
        self, issue_description: str, context_docs: List[Dict], resarch_content: str
    ) -> str:
        """OpenAI gpt-4 ëª¨ë¸ë¡œ í•´ê²°ì±…ìƒì„±

        ê¸°ì¡´ì— tavilyì—ì„œ ì™¸ë¶€ research í•œê²ƒì„ í¬í•¨í•˜ì—¬ ì´ìŠˆ í•´ê²° ì¤€ë¹„"""

        # ì½”ë“œ ì§ˆì˜
        code_context = ""
        for i, doc in enumerate(context_docs, 1):
            code_context += f"Code Snippet {i}:\n"
            code_context += f"File: {doc['metadata'].get('source','Unknown')}\n"
            code_context += (
                f"File Type: {doc['metadata'].get('file_type', 'Unknown')}\n"
            )
            code_context += f"Similarity Score: {doc['similarity_score']:.3f}\n"
            code_context += f"Content:\n{doc['content']}\n"
            code_context += "-" * 50 + "\n"

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ Spring Bootì™€ Kotlinì— ì „ë¬¸ì„±ì„ ê°€ì§„ ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤. 
        ì£¼ì–´ì§„ ì´ìŠˆì— ëŒ€í•´ ì½”ë“œ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

        ì‘ë‹µ í˜•ì‹:
        1. ë¬¸ì œ ë¶„ì„
        2. ì›ì¸ íŒŒì•…  
        3. í•´ê²° ë°©ì•ˆ
        4. ì½”ë“œ ì˜ˆì‹œ (í•„ìš”í•œ ê²½ìš°)
        5. ì¶”ê°€ ê¶Œì¥ì‚¬í•­

        í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        # ìœ ì € í”„ë¡¬í”„íŠ¸
        user_prompt = f"""
        ì´ìŠˆ ì„¤ëª… : 
        {issue_description}
        ê´€ë ¨ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ :
        {code_context}
        ì™¸ë¶€ ë¦¬ì„œì¹˜ ê²°ê³¼ :
        {resarch_content}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ìŠˆì— ëŒ€í•œ ì¢…í•©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
        """

        try:
            # LangChainì„ í™œìš©í•˜ì—¬ ì¶”í›„ LangSmith ì¶”ì ì— ì‚¬ìš©
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt),
            ]

            response = self.llm.invoke(messages)
            solution = response.content
            return solution
        except Exception as e:
            print(f" Error generate : {e}")
            return f"ì†”ë£¨ì…˜ ìƒì„±ì¤‘ ì—ëŸ¬ ë°œìƒ : {e}"

    def resolve_issue(self, issue_description: str) -> Dict[str, Any]:
        """ì „ì²´ ì´ìŠˆ í•´ê²° íŒŒì´í”„ë¼ì¸"""
        print(f"Starting issue resolution for: {issue_description}")

        # 1. ê´€ë ¨ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        context_docs = self.search_relevant_context(issue_description)

        # 2. ì™¸ë¶€ ë¦¬ì„œì¹˜ ìˆ˜í–‰
        research_query = f"spring boot kotlin {issue_description} solution"
        research_content = self.tavily_resarch(research_query)

        # 3. í•´ê²°ì±… ìƒì„±
        solution = self.generate_solution(
            issue_description, context_docs, research_content
        )

        # ê²°ê³¼ ì •ë¦¬
        result = {
            "issue": issue_description,
            "relevant_files": [
                doc["metadata"].get("source", "Unknown") for doc in context_docs
            ],
            "context_docs": context_docs,
            "research_content": research_content,
            "solution": solution,
        }

        print("Issue resolution completed!")
        return result

    def print_resolution_report(self, result: Dict[str, Any]) -> None:
        """í•´ê²°ì±… ë¦¬í¬íŠ¸ë¥¼ report/result-query.md íŒŒì¼ì— ì €ì¥"""

        # report ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("report", exist_ok=True)

        # ë¦¬í¬íŠ¸ ë‚´ìš© ìƒì„±
        report_content = f"""# Issue Resolution Report

        **Generated on:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

        ## ğŸ¯ Issue
        {result['issue']}

        ## ğŸ“ Relevant Files ({len(result['relevant_files'])})
        """

        for file in result["relevant_files"][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            report_content += f"- {file}\n"

        report_content += f"\n## ğŸ¤– Solution\n{result['solution']}\n"

        if (
            result["research_content"]
            and "External research unavailable" not in result["research_content"]
        ):
            report_content += f"\n## ğŸŒ External Research\n"
            research_lines = result["research_content"].split("\n")[:10]  # ì²˜ìŒ 10ì¤„ë§Œ
            report_content += "\n".join(research_lines)
            if len(result["research_content"].split("\n")) > 10:
                report_content += "\n\n... (more research results available)"

        # íŒŒì¼ì— ì €ì¥
        with open("report/result-query.md", "w", encoding="utf-8") as f:
            f.write(report_content)

        print(f"âœ… Resolution report saved to: report/result-query.md")


def main():
    parser = argparse.ArgumentParser(description="Issue Resolve Parser")
    parser.add_argument(
        "--issue", required=True, help="Issue description or issue number save to me"
    )
    parser.add_argument(
        "--persist-dir",
        help="if you need to cetain chromDB check this option",
        default="./chroma_db",
    )

    args = parser.parse_args()

    if args.persist_dir:
        os.environ["CHROMA_PERSIST_DIRECTORY"] = args.persist_dir

    try:
        # ì¿¼ë¦¬ ì´ˆê¸°í™”
        query_system = IssueQuerySystem()

        # ì´ìŠˆ í•´ê²°
        result = query_system.resolve_issue(args.issue)

        # ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥
        query_system.print_resolution_report(result)
        print(f"Issue resolution completed successfully!")

    except Exception as e:
        print(f"Query ì‹¤í–‰ì¤‘ ì‹¤íŒ¨ ìƒì„¸ ì´ìœ : {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
